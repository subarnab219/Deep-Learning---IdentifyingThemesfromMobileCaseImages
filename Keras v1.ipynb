{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2016)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_im_cv2(path):\n",
    "    img = cv2.imread(path)\n",
    "    height, width, channels = img.shape\n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train():\n",
    "    X_train = []\n",
    "    X_train_id = []\n",
    "    y_train = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('Read train images')\n",
    "    folders = ['Automobile',\n",
    "               'Comics_and_Cartoons',\n",
    "               'Famous_Personalities',\n",
    "               'Festivals_and_Occasions',\n",
    "               'Graffiti_and_Illustrations',\n",
    "               'Movies_and_TV_shows',\n",
    "               'Music',\n",
    "               'Nature',\n",
    "               'No_Theme',\n",
    "               'Patterns_and_Ethnic',\n",
    "               'Signs_and_Symbols',\n",
    "               'Spiritual',\n",
    "               'Sports',\n",
    "               'Superheroes',\n",
    "               'Typography',\n",
    "               'Vintage'\n",
    "              ]\n",
    "    for fld in folders:\n",
    "        index = folders.index(fld)\n",
    "        print('Load folder {} (Index: {})'.format(fld, index))\n",
    "        path = os.path.join('D:\\Misc\\CrowdAnalytix\\Identifying Themes from Mobile Case Images\\Data Raw\\Train', fld, '*.jpg')\n",
    "        files = glob.glob(path)\n",
    "        for i in range(len(files)):\n",
    "            flbase = os.path.basename(files[i])\n",
    "            img = get_im_cv2(files[i])\n",
    "            X_train.append(img)\n",
    "            X_train_id.append(flbase)\n",
    "            y_train.append(index) \n",
    "    print len(X_train)\n",
    "    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return X_train, y_train, X_train_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test():\n",
    "    path = os.path.join('D:\\Misc\\CrowdAnalytix\\Identifying Themes from Mobile Case Images\\Data Raw\\Test', '*.jpg')\n",
    "    files = sorted(glob.glob(path))\n",
    "\n",
    "    X_test = []\n",
    "    X_test_id = []\n",
    "    for fl in files:\n",
    "        flbase = os.path.basename(fl)\n",
    "        img = get_im_cv2(fl)\n",
    "        X_test.append(img)\n",
    "        X_test_id.append(flbase)\n",
    "\n",
    "    return X_test, X_test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train images\n",
      "Load folder Automobile (Index: 0)\n",
      "Load folder Comics_and_Cartoons (Index: 1)\n",
      "Load folder Famous_Personalities (Index: 2)\n",
      "Load folder Festivals_and_Occasions (Index: 3)\n",
      "Load folder Graffiti_and_Illustrations (Index: 4)\n",
      "Load folder Movies_and_TV_shows (Index: 5)\n",
      "Load folder Music (Index: 6)\n",
      "Load folder Nature (Index: 7)\n",
      "Load folder No_Theme (Index: 8)\n",
      "Load folder Patterns_and_Ethnic (Index: 9)\n",
      "Load folder Signs_and_Symbols (Index: 10)\n",
      "Load folder Spiritual (Index: 11)\n",
      "Load folder Sports (Index: 12)\n",
      "Load folder Superheroes (Index: 13)\n",
      "Load folder Typography (Index: 14)\n",
      "Load folder Vintage (Index: 15)\n",
      "4592\n",
      "Read train data time: 168.19 seconds\n"
     ]
    }
   ],
   "source": [
    "Xtrall, Ytrall, Itrall = load_train()\n",
    "X_test, X_test_id = load_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten out all images to be one-dimensional\n",
    "Xtrall = np.array(Xtrall, dtype=np.uint8)\n",
    "Ytrall = np.array(Ytrall, dtype=np.uint8)\n",
    "\n",
    "Xtrall = Xtrall.astype('float32')\n",
    "Xtrall = Xtrall / 255\n",
    "Xtrall = Xtrall.transpose((0, 3, 1, 2))\n",
    "\n",
    "msk = np.random.rand(len(Xtrall)) < 0.8\n",
    "Xval = Xtrall[~msk]\n",
    "Yval = Ytrall[~msk]\n",
    "Ytr = Ytrall[msk]\n",
    "Xtr = Xtrall[msk]\n",
    "\n",
    "X_test = np.array(X_test, dtype=np.uint8)\n",
    "\n",
    "X_test = X_test.astype('float32')\n",
    "X_test = X_test / 255\n",
    "X_test = X_test.transpose((0, 3, 1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ytr = np_utils.to_categorical(Ytr, 16)\n",
    "Yval = np_utils.to_categorical(Yval, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "nb_classes=len(Ytr)\n",
    "nb_epoch=30\n",
    "nb_filters=32\n",
    "nb_pool=1\n",
    "nb_conv=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(Convolution2D(nb_filters,nb_conv,nb_conv,border_mode='same',input_shape=Xtr.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters,nb_conv,nb_conv))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool,nb_pool)))\n",
    "model.add(Dropout(0.5));\n",
    "model.add(Flatten());\n",
    "model.add(Dense(128));\n",
    "model.add(Dropout(0.5));\n",
    "model.add(Dense(16));\n",
    "model.add(Activation('softmax'));\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3700 samples, validate on 892 samples\n",
      "Epoch 1/30\n",
      "3700/3700 [==============================] - 30s - loss: 2.0300 - acc: 0.4035 - val_loss: 1.6489 - val_acc: 0.5258\n",
      "Epoch 2/30\n",
      "3700/3700 [==============================] - 28s - loss: 1.6307 - acc: 0.5311 - val_loss: 1.5330 - val_acc: 0.5482\n",
      "Epoch 3/30\n",
      "3700/3700 [==============================] - 28s - loss: 1.4304 - acc: 0.5849 - val_loss: 1.4134 - val_acc: 0.5897\n",
      "Epoch 4/30\n",
      "3700/3700 [==============================] - 28s - loss: 1.2525 - acc: 0.6251 - val_loss: 1.5281 - val_acc: 0.5504\n",
      "Epoch 5/30\n",
      "3700/3700 [==============================] - 29s - loss: 1.1240 - acc: 0.6762 - val_loss: 1.3460 - val_acc: 0.6110\n",
      "Epoch 6/30\n",
      "3700/3700 [==============================] - 29s - loss: 0.9980 - acc: 0.7032 - val_loss: 1.3606 - val_acc: 0.6323\n",
      "Epoch 7/30\n",
      "3700/3700 [==============================] - 29s - loss: 0.8815 - acc: 0.7392 - val_loss: 1.3859 - val_acc: 0.6065\n",
      "Epoch 8/30\n",
      "3700/3700 [==============================] - 29s - loss: 0.8024 - acc: 0.7597 - val_loss: 1.3458 - val_acc: 0.6166\n",
      "Epoch 9/30\n",
      "3700/3700 [==============================] - 29s - loss: 0.7181 - acc: 0.7808 - val_loss: 1.3483 - val_acc: 0.6143\n",
      "Epoch 10/30\n",
      "3700/3700 [==============================] - 29s - loss: 0.6320 - acc: 0.8097 - val_loss: 1.4226 - val_acc: 0.6166\n",
      "Epoch 11/30\n",
      "3700/3700 [==============================] - 29s - loss: 0.5775 - acc: 0.8284 - val_loss: 1.4338 - val_acc: 0.6166\n",
      "Epoch 12/30\n",
      "3700/3700 [==============================] - 29s - loss: 0.5232 - acc: 0.8359 - val_loss: 1.4249 - val_acc: 0.6289\n",
      "Epoch 13/30\n",
      "3700/3700 [==============================] - 30s - loss: 0.5083 - acc: 0.8427 - val_loss: 1.4486 - val_acc: 0.6401\n",
      "Epoch 14/30\n",
      "3700/3700 [==============================] - 29s - loss: 0.4544 - acc: 0.8559 - val_loss: 1.4440 - val_acc: 0.6244\n",
      "Epoch 15/30\n",
      "3700/3700 [==============================] - 30s - loss: 0.4293 - acc: 0.8708 - val_loss: 1.5078 - val_acc: 0.6401\n",
      "Epoch 16/30\n",
      "3700/3700 [==============================] - 30s - loss: 0.3927 - acc: 0.8824 - val_loss: 1.4647 - val_acc: 0.6424\n",
      "Epoch 17/30\n",
      "3700/3700 [==============================] - 30s - loss: 0.3770 - acc: 0.8800 - val_loss: 1.5490 - val_acc: 0.6244\n",
      "Epoch 18/30\n",
      "3700/3700 [==============================] - 30s - loss: 0.3532 - acc: 0.8946 - val_loss: 1.5956 - val_acc: 0.6065\n",
      "Epoch 19/30\n",
      "3700/3700 [==============================] - 30s - loss: 0.3179 - acc: 0.9005 - val_loss: 1.6136 - val_acc: 0.6244\n",
      "Epoch 20/30\n",
      "3700/3700 [==============================] - 30s - loss: 0.3063 - acc: 0.9092 - val_loss: 1.6918 - val_acc: 0.6076\n",
      "Epoch 21/30\n",
      "3700/3700 [==============================] - 30s - loss: 0.2899 - acc: 0.9114 - val_loss: 1.7544 - val_acc: 0.6155\n",
      "Epoch 22/30\n",
      "3700/3700 [==============================] - 30s - loss: 0.2842 - acc: 0.9092 - val_loss: 1.8035 - val_acc: 0.6043\n",
      "Epoch 23/30\n",
      "3700/3700 [==============================] - 31s - loss: 0.2603 - acc: 0.9219 - val_loss: 1.6186 - val_acc: 0.6256\n",
      "Epoch 24/30\n",
      "3700/3700 [==============================] - 34s - loss: 0.2703 - acc: 0.9173 - val_loss: 1.7423 - val_acc: 0.6390\n",
      "Epoch 25/30\n",
      "3700/3700 [==============================] - 32s - loss: 0.2662 - acc: 0.9184 - val_loss: 1.6947 - val_acc: 0.6345\n",
      "Epoch 26/30\n",
      "3700/3700 [==============================] - 33s - loss: 0.2446 - acc: 0.9265 - val_loss: 1.6566 - val_acc: 0.6278\n",
      "Epoch 27/30\n",
      "3700/3700 [==============================] - 32s - loss: 0.2295 - acc: 0.9327 - val_loss: 1.7195 - val_acc: 0.6244\n",
      "Epoch 28/30\n",
      "3700/3700 [==============================] - 31s - loss: 0.2298 - acc: 0.9324 - val_loss: 1.7553 - val_acc: 0.6312\n",
      "Epoch 29/30\n",
      "3700/3700 [==============================] - 32s - loss: 0.2334 - acc: 0.9297 - val_loss: 1.8531 - val_acc: 0.6278\n",
      "Epoch 30/30\n",
      "3700/3700 [==============================] - 32s - loss: 0.2184 - acc: 0.9330 - val_loss: 1.7032 - val_acc: 0.6267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x191b54a8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtr,Ytr,batch_size=batch_size,nb_epoch=nb_epoch,verbose=1,validation_data=(Xval, Yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "predictions = model.predict(X_test,batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\"0\":\"Automobile\",\"1\":\"Comics_and_Cartoons\",\"2\":\"Famous_Personalities\",\"3\":\"Festivals_and_Occasions\",\n",
    "              \"4\":\"Graffiti_and_Illustrations\",\"5\":\"Movies_and_TV_shows\",\"6\":\"Music\",\"7\":\"Nature\",\"8\":\"No_Theme\",\n",
    "              \"9\":\"Patterns_and_Ethnic\",\"10\":\"Signs_and_Symbols\",\"11\":\"Spiritual\",\"12\":\"Sports\",\"13\":\"Superheroes\",\n",
    "              \"14\":\"Typography\",\"15\":\"Vintage\"}\n",
    "    \n",
    "y = np.array([params[str(i)] for i in np.argmax(predictions, axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = pd.DataFrame(X_test_id, columns=['id'])\n",
    "result1.loc[:, 'Mobile_Theme'] = pd.Series(y, index=result1.index)\n",
    "now = datetime.datetime.now()\n",
    "sub_file = 'submission_keras_v1' +  '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "result1.to_csv(sub_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
