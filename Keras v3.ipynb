{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2016)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "%matplotlib inline \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_im_cv2(path):\n",
    "    img = cv2.imread(path)\n",
    "    height, width, channels = img.shape\n",
    "    img = cv2.resize(img, (64, 64))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train():\n",
    "    X_train = []\n",
    "    X_train_id = []\n",
    "    y_train = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('Read train images')\n",
    "    folders = ['Automobile',\n",
    "               'Comics_and_Cartoons',\n",
    "               'Famous_Personalities',\n",
    "               'Festivals_and_Occasions',\n",
    "               'Graffiti_and_Illustrations',\n",
    "               'Movies_and_TV_shows',\n",
    "               'Music',\n",
    "               'Nature',\n",
    "               'No_Theme',\n",
    "               'Patterns_and_Ethnic',\n",
    "               'Signs_and_Symbols',\n",
    "               'Spiritual',\n",
    "               'Sports',\n",
    "               'Superheroes',\n",
    "               'Typography',\n",
    "               'Vintage'\n",
    "              ]\n",
    "    for fld in folders:\n",
    "        index = folders.index(fld)\n",
    "        print('Load folder {} (Index: {})'.format(fld, index))\n",
    "        path = os.path.join('D:\\Misc\\CrowdAnalytix\\Identifying Themes from Mobile Case Images\\Data Raw\\Train', fld, '*.jpg')\n",
    "        files = glob.glob(path)\n",
    "        for i in range(len(files)):\n",
    "            flbase = os.path.basename(files[i])\n",
    "            img = get_im_cv2(files[i])\n",
    "            X_train.append(img)\n",
    "            X_train_id.append(flbase)\n",
    "            y_train.append(index) \n",
    "    print len(X_train)\n",
    "    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return X_train, y_train, X_train_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test():\n",
    "    path = os.path.join('D:\\Misc\\CrowdAnalytix\\Identifying Themes from Mobile Case Images\\Data Raw\\Test', '*.jpg')\n",
    "    files = sorted(glob.glob(path))\n",
    "\n",
    "    X_test = []\n",
    "    X_test_id = []\n",
    "    for fl in files:\n",
    "        flbase = os.path.basename(fl)\n",
    "        img = get_im_cv2(fl)\n",
    "        X_test.append(img)\n",
    "        X_test_id.append(flbase)\n",
    "\n",
    "    return X_test, X_test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train images\n",
      "Load folder Automobile (Index: 0)\n",
      "Load folder Comics_and_Cartoons (Index: 1)\n",
      "Load folder Famous_Personalities (Index: 2)\n",
      "Load folder Festivals_and_Occasions (Index: 3)\n",
      "Load folder Graffiti_and_Illustrations (Index: 4)\n",
      "Load folder Movies_and_TV_shows (Index: 5)\n",
      "Load folder Music (Index: 6)\n",
      "Load folder Nature (Index: 7)\n",
      "Load folder No_Theme (Index: 8)\n",
      "Load folder Patterns_and_Ethnic (Index: 9)\n",
      "Load folder Signs_and_Symbols (Index: 10)\n",
      "Load folder Spiritual (Index: 11)\n",
      "Load folder Sports (Index: 12)\n",
      "Load folder Superheroes (Index: 13)\n",
      "Load folder Typography (Index: 14)\n",
      "Load folder Vintage (Index: 15)\n",
      "4592\n",
      "Read train data time: 70.57 seconds\n"
     ]
    }
   ],
   "source": [
    "Xtrall, Ytrall, Itrall = load_train()\n",
    "X_test, X_test_id = load_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten out all images to be one-dimensional\n",
    "Xtrall = np.array(Xtrall, dtype=np.uint8)\n",
    "Ytrall = np.array(Ytrall, dtype=np.uint8)\n",
    "\n",
    "Xtrall = Xtrall.astype('float32')\n",
    "Xtrall = Xtrall / 255\n",
    "Xtrall = Xtrall.transpose((0, 3, 1, 2))\n",
    "\n",
    "# msk = np.random.rand(len(Xtrall)) < 0.8\n",
    "# Xval = Xtrall[~msk]\n",
    "# Yval = Ytrall[~msk]\n",
    "# Ytr = Ytrall[msk]\n",
    "# Xtr = Xtrall[msk]\n",
    "\n",
    "X_test = np.array(X_test, dtype=np.uint8)\n",
    "\n",
    "X_test = X_test.astype('float32')\n",
    "X_test = X_test / 255\n",
    "X_test = X_test.transpose((0, 3, 1, 2))\n",
    "\n",
    "Ytrall = np_utils.to_categorical(Ytrall, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "nb_classes=len(Ytrall)\n",
    "nb_epoch=30\n",
    "nb_filters=32\n",
    "nb_pool=1\n",
    "nb_conv=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(ZeroPadding2D((1, 1), input_shape=Xtrall.shape[1:]))\n",
    "model.add(Convolution2D(nb_filters,nb_conv,nb_conv, subsample=(1, 1),activation='relu'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5));\n",
    "model.add(Flatten());\n",
    "model.add(Dense(64));\n",
    "model.add(Dropout(0.5));\n",
    "model.add(Dense(16));\n",
    "model.add(Activation('softmax'));\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start KFold number 1 from 10\n",
      "('Split train: ', 4132, 4132)\n",
      "('Split valid: ', 460, 460)\n",
      "Train on 4132 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "45s - loss: 0.2196 - acc: 0.9349 - val_loss: 1.6271 - val_acc: 0.6674\n",
      "Epoch 2/30\n",
      "42s - loss: 0.2119 - acc: 0.9359 - val_loss: 1.6086 - val_acc: 0.6587\n",
      "Epoch 3/30\n",
      "43s - loss: 0.2067 - acc: 0.9417 - val_loss: 1.8065 - val_acc: 0.6478\n",
      "Epoch 4/30\n",
      "45s - loss: 0.2187 - acc: 0.9342 - val_loss: 1.6432 - val_acc: 0.6326\n",
      "Epoch 5/30\n",
      "43s - loss: 0.2083 - acc: 0.9378 - val_loss: 1.6762 - val_acc: 0.6565\n",
      "Epoch 6/30\n",
      "43s - loss: 0.1992 - acc: 0.9402 - val_loss: 1.6897 - val_acc: 0.6587\n",
      "('Score log_loss: ', 1.6896935279588863)\n",
      "Start KFold number 2 from 10\n",
      "('Split train: ', 4132, 4132)\n",
      "('Split valid: ', 460, 460)\n",
      "Train on 4132 samples, validate on 460 samples\n",
      "Epoch 1/30\n",
      "42s - loss: 0.3784 - acc: 0.9083 - val_loss: 0.1257 - val_acc: 0.9652\n",
      "Epoch 2/30\n",
      "41s - loss: 0.3209 - acc: 0.9160 - val_loss: 0.1567 - val_acc: 0.9500\n",
      "Epoch 3/30\n",
      "42s - loss: 0.2846 - acc: 0.9211 - val_loss: 0.1778 - val_acc: 0.9457\n",
      "Epoch 4/30\n",
      "42s - loss: 0.2511 - acc: 0.9303 - val_loss: 0.2004 - val_acc: 0.9522\n",
      "Epoch 5/30\n",
      "42s - loss: 0.2345 - acc: 0.9318 - val_loss: 0.2212 - val_acc: 0.9391\n",
      "('Score log_loss: ', 0.22119610664958647)\n",
      "Start KFold number 3 from 10\n",
      "('Split train: ', 4133, 4133)\n",
      "('Split valid: ', 459, 459)\n",
      "Train on 4133 samples, validate on 459 samples\n",
      "Epoch 1/30\n",
      "42s - loss: 0.2435 - acc: 0.9289 - val_loss: 0.0975 - val_acc: 0.9564\n",
      "Epoch 2/30\n",
      "42s - loss: 0.2181 - acc: 0.9339 - val_loss: 0.1160 - val_acc: 0.9499\n",
      "Epoch 3/30\n",
      "42s - loss: 0.2088 - acc: 0.9373 - val_loss: 0.1641 - val_acc: 0.9455\n",
      "Epoch 4/30\n",
      "42s - loss: 0.1946 - acc: 0.9434 - val_loss: 0.1806 - val_acc: 0.9325\n",
      "Epoch 5/30\n",
      "41s - loss: 0.1909 - acc: 0.9448 - val_loss: 0.1978 - val_acc: 0.9346\n",
      "('Score log_loss: ', 0.19784701096822233)\n",
      "Start KFold number 4 from 10\n",
      "('Split train: ', 4133, 4133)\n",
      "('Split valid: ', 459, 459)\n",
      "Train on 4133 samples, validate on 459 samples\n",
      "Epoch 1/30\n",
      "41s - loss: 0.1840 - acc: 0.9429 - val_loss: 0.0882 - val_acc: 0.9564\n",
      "Epoch 2/30\n",
      "41s - loss: 0.1911 - acc: 0.9444 - val_loss: 0.1230 - val_acc: 0.9434\n",
      "Epoch 3/30\n",
      "41s - loss: 0.1790 - acc: 0.9436 - val_loss: 0.1367 - val_acc: 0.9499\n",
      "Epoch 4/30\n",
      "41s - loss: 0.1839 - acc: 0.9458 - val_loss: 0.1673 - val_acc: 0.9368\n",
      "Epoch 5/30\n",
      "41s - loss: 0.1764 - acc: 0.9460 - val_loss: 0.1673 - val_acc: 0.9390\n",
      "('Score log_loss: ', 0.16727748564403994)\n",
      "Start KFold number 5 from 10\n",
      "('Split train: ', 4133, 4133)\n",
      "('Split valid: ', 459, 459)\n",
      "Train on 4133 samples, validate on 459 samples\n",
      "Epoch 1/30\n",
      "41s - loss: 0.1710 - acc: 0.9458 - val_loss: 0.1303 - val_acc: 0.9499\n",
      "Epoch 2/30\n",
      "42s - loss: 0.1769 - acc: 0.9460 - val_loss: 0.1281 - val_acc: 0.9368\n",
      "Epoch 3/30\n",
      "41s - loss: 0.1554 - acc: 0.9543 - val_loss: 0.1953 - val_acc: 0.9216\n",
      "Epoch 4/30\n",
      "41s - loss: 0.1512 - acc: 0.9548 - val_loss: 0.1985 - val_acc: 0.9172\n",
      "Epoch 5/30\n",
      "41s - loss: 0.1588 - acc: 0.9567 - val_loss: 0.2093 - val_acc: 0.9172\n",
      "Epoch 6/30\n",
      "41s - loss: 0.1675 - acc: 0.9540 - val_loss: 0.2692 - val_acc: 0.9107\n",
      "('Score log_loss: ', 0.26924968185915304)\n",
      "Start KFold number 6 from 10\n",
      "('Split train: ', 4133, 4133)\n",
      "('Split valid: ', 459, 459)\n",
      "Train on 4133 samples, validate on 459 samples\n",
      "Epoch 1/30\n",
      "42s - loss: 0.1714 - acc: 0.9511 - val_loss: 0.1148 - val_acc: 0.9564\n",
      "Epoch 2/30\n",
      "42s - loss: 0.1674 - acc: 0.9489 - val_loss: 0.1407 - val_acc: 0.9586\n",
      "Epoch 3/30\n",
      "42s - loss: 0.1641 - acc: 0.9535 - val_loss: 0.1506 - val_acc: 0.9521\n",
      "Epoch 4/30\n",
      "42s - loss: 0.1627 - acc: 0.9506 - val_loss: 0.1757 - val_acc: 0.9412\n",
      "Epoch 5/30\n",
      "41s - loss: 0.1694 - acc: 0.9506 - val_loss: 0.1775 - val_acc: 0.9455\n",
      "('Score log_loss: ', 0.17750072852954751)\n",
      "Start KFold number 7 from 10\n",
      "('Split train: ', 4133, 4133)\n",
      "('Split valid: ', 459, 459)\n",
      "Train on 4133 samples, validate on 459 samples\n",
      "Epoch 1/30\n",
      "41s - loss: 0.1591 - acc: 0.9492 - val_loss: 0.1058 - val_acc: 0.9521\n",
      "Epoch 2/30\n",
      "41s - loss: 0.1640 - acc: 0.9519 - val_loss: 0.1457 - val_acc: 0.9368\n",
      "Epoch 3/30\n",
      "41s - loss: 0.1501 - acc: 0.9543 - val_loss: 0.1729 - val_acc: 0.9412\n",
      "Epoch 4/30\n",
      "41s - loss: 0.1480 - acc: 0.9574 - val_loss: 0.1929 - val_acc: 0.9368\n",
      "Epoch 5/30\n",
      "42s - loss: 0.1598 - acc: 0.9550 - val_loss: 0.2043 - val_acc: 0.9325\n",
      "('Score log_loss: ', 0.20430867115782259)\n",
      "Start KFold number 8 from 10\n",
      "('Split train: ', 4133, 4133)\n",
      "('Split valid: ', 459, 459)\n",
      "Train on 4133 samples, validate on 459 samples\n",
      "Epoch 1/30\n",
      "41s - loss: 0.1549 - acc: 0.9545 - val_loss: 0.1123 - val_acc: 0.9521\n",
      "Epoch 2/30\n",
      "41s - loss: 0.1462 - acc: 0.9567 - val_loss: 0.1453 - val_acc: 0.9455\n",
      "Epoch 3/30\n",
      "41s - loss: 0.1507 - acc: 0.9540 - val_loss: 0.2004 - val_acc: 0.9412\n",
      "Epoch 4/30\n",
      "41s - loss: 0.1438 - acc: 0.9548 - val_loss: 0.2092 - val_acc: 0.9368\n",
      "Epoch 5/30\n",
      "41s - loss: 0.1497 - acc: 0.9540 - val_loss: 0.2547 - val_acc: 0.9325\n",
      "('Score log_loss: ', 0.2546966889334541)\n",
      "Start KFold number 9 from 10\n",
      "('Split train: ', 4133, 4133)\n",
      "('Split valid: ', 459, 459)\n",
      "Train on 4133 samples, validate on 459 samples\n",
      "Epoch 1/30\n",
      "42s - loss: 0.1484 - acc: 0.9540 - val_loss: 0.0895 - val_acc: 0.9630\n",
      "Epoch 2/30\n",
      "41s - loss: 0.1529 - acc: 0.9548 - val_loss: 0.1107 - val_acc: 0.9608\n",
      "Epoch 3/30\n",
      "41s - loss: 0.1536 - acc: 0.9535 - val_loss: 0.1178 - val_acc: 0.9630\n",
      "Epoch 4/30\n",
      "41s - loss: 0.1624 - acc: 0.9528 - val_loss: 0.1342 - val_acc: 0.9564\n",
      "Epoch 5/30\n",
      "41s - loss: 0.1507 - acc: 0.9555 - val_loss: 0.1307 - val_acc: 0.9586\n",
      "('Score log_loss: ', 0.13070179642781349)\n",
      "Start KFold number 10 from 10\n",
      "('Split train: ', 4133, 4133)\n",
      "('Split valid: ', 459, 459)\n",
      "Train on 4133 samples, validate on 459 samples\n",
      "Epoch 1/30\n",
      "41s - loss: 0.1426 - acc: 0.9564 - val_loss: 0.1031 - val_acc: 0.9499\n",
      "Epoch 2/30\n",
      "41s - loss: 0.1392 - acc: 0.9603 - val_loss: 0.1256 - val_acc: 0.9477\n",
      "Epoch 3/30\n",
      "41s - loss: 0.1489 - acc: 0.9557 - val_loss: 0.1524 - val_acc: 0.9368\n",
      "Epoch 4/30\n",
      "42s - loss: 0.1382 - acc: 0.9591 - val_loss: 0.1858 - val_acc: 0.9390\n",
      "Epoch 5/30\n",
      "43s - loss: 0.1415 - acc: 0.9579 - val_loss: 0.2006 - val_acc: 0.9346\n",
      "('Score log_loss: ', 0.20063975422271951)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-4ee634d45b67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum_score\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Log_loss train independent avg: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "nfolds = 10\n",
    "yfull_train = dict()\n",
    "kf = KFold(len(Itrall), n_folds=10, shuffle=True, random_state=51)\n",
    "num_fold = 0\n",
    "sum_score = 0\n",
    "models = []\n",
    "\n",
    "for mtr,mval in kf:\n",
    "    Xtr = Xtrall[mtr]\n",
    "    Ytr = Ytrall[mtr]\n",
    "    Xval = Xtrall[mval]\n",
    "    Yval = Ytrall[mval]\n",
    "    \n",
    "    num_fold += 1\n",
    "    \n",
    "    print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "    print('Split train: ', len(Xtr), len(Ytr))\n",
    "    print('Split valid: ', len(Xval), len(Yval))\n",
    "    \n",
    "    callbacks = [\n",
    "            EarlyStopping(monitor='val_loss', patience=3, verbose=0),\n",
    "        ]\n",
    "    model.fit(Xtr,Ytr, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "              shuffle=True, verbose=2, validation_data=(Xval, Yval),\n",
    "              callbacks=callbacks)\n",
    "    predictions_valid = model.predict(Xval.astype('float32'), batch_size=batch_size, verbose=2)\n",
    "    score = log_loss(Yval, predictions_valid)\n",
    "    print('Score log_loss: ', score)\n",
    "    sum_score += score*len(mval)\n",
    "    \n",
    "    # Store valid predictions\n",
    "    for i in range(len(mval)):\n",
    "        yfull_train[mval[i]] = predictions_valid[i]\n",
    "\n",
    "    models.append(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Log_loss train independent avg: ', 0.35157426965675742)\n"
     ]
    }
   ],
   "source": [
    "score = sum_score/len(Xtrall)\n",
    "print(\"Log_loss train independent avg: \", score)\n",
    "\n",
    "info_string = 'loss_' + str(score) + '_folds_' + str(10) + '_ep_' + str(nb_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start KFold number 1 from 10\n",
      "Start KFold number 2 from 10\n",
      "Start KFold number 3 from 10\n",
      "Start KFold number 4 from 10\n",
      "Start KFold number 5 from 10\n",
      "Start KFold number 6 from 10\n",
      "Start KFold number 7 from 10\n",
      "Start KFold number 8 from 10\n",
      "Start KFold number 9 from 10\n",
      "Start KFold number 10 from 10\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_fold = 0\n",
    "yfull_test = []\n",
    "test_id = []\n",
    "nfolds = len(models)\n",
    "\n",
    "for i in range(nfolds):\n",
    "    model = models[i]\n",
    "    num_fold += 1\n",
    "    print('Start KFold number {} from {}'.format(num_fold, nfolds))\n",
    "    test_prediction = model.predict(X_test, batch_size=batch_size, verbose=2)\n",
    "    yfull_test.append(test_prediction)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array(yfull_test[0])\n",
    "for i in range(1, nfolds):\n",
    "    a += np.array(yfull_test[i])\n",
    "a /= nfolds\n",
    "test_res = a.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "info_string = 'loss_' + info_string \\\n",
    "                + '_folds_' + str(nfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Graffiti_and_Illustrations' 'Typography' 'Comics_and_Cartoons' ...,\n",
      " 'Patterns_and_Ethnic' 'Signs_and_Symbols' 'Nature']\n"
     ]
    }
   ],
   "source": [
    "params = {\"0\":\"Automobile\",\"1\":\"Comics_and_Cartoons\",\"2\":\"Famous_Personalities\",\"3\":\"Festivals_and_Occasions\",\n",
    "              \"4\":\"Graffiti_and_Illustrations\",\"5\":\"Movies_and_TV_shows\",\"6\":\"Music\",\"7\":\"Nature\",\"8\":\"No_Theme\",\n",
    "              \"9\":\"Patterns_and_Ethnic\",\"10\":\"Signs_and_Symbols\",\"11\":\"Spiritual\",\"12\":\"Sports\",\"13\":\"Superheroes\",\n",
    "              \"14\":\"Typography\",\"15\":\"Vintage\"}\n",
    "    \n",
    "y = np.array([params[str(i)] for i in np.argmax(test_res, axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result1 = pd.DataFrame(X_test_id, columns=['id'])\n",
    "result1.loc[:, 'Mobile_Theme'] = pd.Series(y, index=result1.index)\n",
    "now = datetime.datetime.now()\n",
    "sub_file = 'submission_keras_v1' +'_'+info_string+  '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "result1.to_csv(sub_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
