{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2016)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "%matplotlib inline \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_im_cv2(path):\n",
    "    img = cv2.imread(path)\n",
    "    height, width, channels = img.shape\n",
    "    img = cv2.resize(img, (64, 64))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train():\n",
    "    X_train = []\n",
    "    X_train_id = []\n",
    "    y_train = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('Read train images')\n",
    "    folders = ['Automobile',\n",
    "               'Comics_and_Cartoons',\n",
    "               'Famous_Personalities',\n",
    "               'Festivals_and_Occasions',\n",
    "               'Graffiti_and_Illustrations',\n",
    "               'Movies_and_TV_shows',\n",
    "               'Music',\n",
    "               'Nature',\n",
    "               'No_Theme',\n",
    "               'Patterns_and_Ethnic',\n",
    "               'Signs_and_Symbols',\n",
    "               'Spiritual',\n",
    "               'Sports',\n",
    "               'Superheroes',\n",
    "               'Typography',\n",
    "               'Vintage'\n",
    "              ]\n",
    "    for fld in folders:\n",
    "        index = folders.index(fld)\n",
    "        print('Load folder {} (Index: {})'.format(fld, index))\n",
    "        path = os.path.join('D:\\Misc\\CrowdAnalytix\\Identifying Themes from Mobile Case Images\\Data Raw\\Train', fld, '*.jpg')\n",
    "        files = glob.glob(path)\n",
    "        for i in range(len(files)):\n",
    "            flbase = os.path.basename(files[i])\n",
    "            img = get_im_cv2(files[i])\n",
    "            X_train.append(img)\n",
    "            X_train_id.append(flbase)\n",
    "            y_train.append(index) \n",
    "    print len(X_train)\n",
    "    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    return X_train, y_train, X_train_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test():\n",
    "    path = os.path.join('D:\\Misc\\CrowdAnalytix\\Identifying Themes from Mobile Case Images\\Data Raw\\Test', '*.jpg')\n",
    "    files = sorted(glob.glob(path))\n",
    "\n",
    "    X_test = []\n",
    "    X_test_id = []\n",
    "    for fl in files:\n",
    "        flbase = os.path.basename(fl)\n",
    "        img = get_im_cv2(fl)\n",
    "        X_test.append(img)\n",
    "        X_test_id.append(flbase)\n",
    "\n",
    "    return X_test, X_test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train images\n",
      "Load folder Automobile (Index: 0)\n",
      "Load folder Comics_and_Cartoons (Index: 1)\n",
      "Load folder Famous_Personalities (Index: 2)\n",
      "Load folder Festivals_and_Occasions (Index: 3)\n",
      "Load folder Graffiti_and_Illustrations (Index: 4)\n",
      "Load folder Movies_and_TV_shows (Index: 5)\n",
      "Load folder Music (Index: 6)\n",
      "Load folder Nature (Index: 7)\n",
      "Load folder No_Theme (Index: 8)\n",
      "Load folder Patterns_and_Ethnic (Index: 9)\n",
      "Load folder Signs_and_Symbols (Index: 10)\n",
      "Load folder Spiritual (Index: 11)\n",
      "Load folder Sports (Index: 12)\n",
      "Load folder Superheroes (Index: 13)\n",
      "Load folder Typography (Index: 14)\n",
      "Load folder Vintage (Index: 15)\n",
      "4592\n",
      "Read train data time: 286.95 seconds\n"
     ]
    }
   ],
   "source": [
    "Xtrall, Ytrall, Itrall = load_train()\n",
    "X_test, X_test_id = load_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten out all images to be one-dimensional\n",
    "Xtrall = np.array(Xtrall, dtype=np.uint8)\n",
    "Ytrall = np.array(Ytrall, dtype=np.uint8)\n",
    "\n",
    "Xtrall = Xtrall.astype('float32')\n",
    "Xtrall = Xtrall / 255\n",
    "Xtrall = Xtrall.transpose((0, 3, 1, 2))\n",
    "\n",
    "msk = np.random.rand(len(Xtrall)) < 0.8\n",
    "Xval = Xtrall[~msk]\n",
    "Yval = Ytrall[~msk]\n",
    "Ytr = Ytrall[msk]\n",
    "Xtr = Xtrall[msk]\n",
    "\n",
    "X_test = np.array(X_test, dtype=np.uint8)\n",
    "\n",
    "X_test = X_test.astype('float32')\n",
    "X_test = X_test / 255\n",
    "X_test = X_test.transpose((0, 3, 1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ytr = np_utils.to_categorical(Ytr, 16)\n",
    "Yval = np_utils.to_categorical(Yval, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "nb_classes=len(Ytr)\n",
    "nb_epoch=30\n",
    "nb_filters=32\n",
    "nb_pool=1\n",
    "nb_conv=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(Convolution2D(nb_filters,nb_conv,nb_conv, subsample=(1, 1), border_mode='valid',input_shape=Xtr.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(nb_filters,nb_conv,nb_conv))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool,nb_pool)))\n",
    "model.add(Dropout(0.5));\n",
    "model.add(Flatten());\n",
    "model.add(Dense(128));\n",
    "model.add(Dropout(0.5));\n",
    "model.add(Dense(16));\n",
    "model.add(Activation('softmax'));\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 16)\n"
     ]
    }
   ],
   "source": [
    "print model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3700 samples, validate on 892 samples\n",
      "Epoch 1/30\n",
      "3700/3700 [==============================] - 123s - loss: 2.1993 - acc: 0.4246 - val_loss: 1.5750 - val_acc: 0.5448\n",
      "Epoch 2/30\n",
      "3700/3700 [==============================] - 128s - loss: 1.5024 - acc: 0.5759 - val_loss: 1.4369 - val_acc: 0.5942\n",
      "Epoch 3/30\n",
      "3700/3700 [==============================] - 131s - loss: 1.2290 - acc: 0.6386 - val_loss: 1.3375 - val_acc: 0.6110\n",
      "Epoch 4/30\n",
      "3700/3700 [==============================] - 123s - loss: 0.9613 - acc: 0.7170 - val_loss: 1.3802 - val_acc: 0.6211\n",
      "Epoch 5/30\n",
      "3700/3700 [==============================] - 124s - loss: 0.7917 - acc: 0.7730 - val_loss: 1.3490 - val_acc: 0.6401\n",
      "Epoch 6/30\n",
      "3700/3700 [==============================] - 124s - loss: 0.6189 - acc: 0.8168 - val_loss: 1.3211 - val_acc: 0.6401\n",
      "Epoch 7/30\n",
      "3700/3700 [==============================] - 125s - loss: 0.5132 - acc: 0.8511 - val_loss: 1.4062 - val_acc: 0.6491\n",
      "Epoch 8/30\n",
      "3700/3700 [==============================] - 130s - loss: 0.4282 - acc: 0.8743 - val_loss: 1.3978 - val_acc: 0.6424\n",
      "Epoch 9/30\n",
      "3700/3700 [==============================] - 129s - loss: 0.3627 - acc: 0.8965 - val_loss: 1.5260 - val_acc: 0.6379\n",
      "Epoch 10/30\n",
      "3700/3700 [==============================] - 120s - loss: 0.3128 - acc: 0.9092 - val_loss: 1.4697 - val_acc: 0.6704\n",
      "Epoch 11/30\n",
      "3700/3700 [==============================] - 120s - loss: 0.2839 - acc: 0.9157 - val_loss: 1.4959 - val_acc: 0.6446\n",
      "Epoch 12/30\n",
      "3700/3700 [==============================] - 133s - loss: 0.2626 - acc: 0.9249 - val_loss: 1.5081 - val_acc: 0.6480\n",
      "Epoch 13/30\n",
      "3700/3700 [==============================] - 134s - loss: 0.2253 - acc: 0.9378 - val_loss: 1.8797 - val_acc: 0.6502\n",
      "Epoch 14/30\n",
      "3700/3700 [==============================] - 129s - loss: 0.2105 - acc: 0.9430 - val_loss: 1.7306 - val_acc: 0.6536\n",
      "Epoch 15/30\n",
      "3700/3700 [==============================] - 126s - loss: 0.2140 - acc: 0.9373 - val_loss: 1.6710 - val_acc: 0.6457\n",
      "Epoch 16/30\n",
      "3700/3700 [==============================] - 130s - loss: 0.1919 - acc: 0.9468 - val_loss: 1.6429 - val_acc: 0.6469\n",
      "Epoch 17/30\n",
      "3700/3700 [==============================] - 130s - loss: 0.1953 - acc: 0.9446 - val_loss: 1.6648 - val_acc: 0.6424\n",
      "Epoch 18/30\n",
      "3700/3700 [==============================] - 126s - loss: 0.1804 - acc: 0.9497 - val_loss: 1.8079 - val_acc: 0.6547\n",
      "Epoch 19/30\n",
      "3700/3700 [==============================] - 119s - loss: 0.1836 - acc: 0.9478 - val_loss: 1.7351 - val_acc: 0.6570\n",
      "Epoch 20/30\n",
      "3700/3700 [==============================] - 115s - loss: 0.1682 - acc: 0.9532 - val_loss: 1.7930 - val_acc: 0.6491\n",
      "Epoch 21/30\n",
      "3700/3700 [==============================] - 108s - loss: 0.1691 - acc: 0.9522 - val_loss: 1.6996 - val_acc: 0.6536\n",
      "Epoch 22/30\n",
      "3700/3700 [==============================] - 109s - loss: 0.1609 - acc: 0.9576 - val_loss: 1.7134 - val_acc: 0.6446\n",
      "Epoch 23/30\n",
      "3700/3700 [==============================] - 108s - loss: 0.1638 - acc: 0.9576 - val_loss: 1.6691 - val_acc: 0.6558\n",
      "Epoch 24/30\n",
      "3700/3700 [==============================] - 107s - loss: 0.1545 - acc: 0.9535 - val_loss: 1.6465 - val_acc: 0.6491\n",
      "Epoch 25/30\n",
      "3700/3700 [==============================] - 107s - loss: 0.1477 - acc: 0.9562 - val_loss: 1.6965 - val_acc: 0.6446\n",
      "Epoch 26/30\n",
      "3700/3700 [==============================] - 107s - loss: 0.1502 - acc: 0.9578 - val_loss: 1.6538 - val_acc: 0.6368\n",
      "Epoch 27/30\n",
      "3700/3700 [==============================] - 107s - loss: 0.1420 - acc: 0.9597 - val_loss: 1.6865 - val_acc: 0.6424\n",
      "Epoch 28/30\n",
      "3700/3700 [==============================] - 108s - loss: 0.1513 - acc: 0.9600 - val_loss: 1.5948 - val_acc: 0.6513\n",
      "Epoch 29/30\n",
      "3700/3700 [==============================] - 108s - loss: 0.1473 - acc: 0.9573 - val_loss: 1.6931 - val_acc: 0.6480\n",
      "Epoch 30/30\n",
      "3700/3700 [==============================] - 107s - loss: 0.1564 - acc: 0.9559 - val_loss: 1.7394 - val_acc: 0.6502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x163f31518>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtr,Ytr,batch_size=batch_size,nb_epoch=nb_epoch,verbose=1,validation_data=(Xval, Yval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "predictions = model.predict(X_test,batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\"0\":\"Automobile\",\"1\":\"Comics_and_Cartoons\",\"2\":\"Famous_Personalities\",\"3\":\"Festivals_and_Occasions\",\n",
    "              \"4\":\"Graffiti_and_Illustrations\",\"5\":\"Movies_and_TV_shows\",\"6\":\"Music\",\"7\":\"Nature\",\"8\":\"No_Theme\",\n",
    "              \"9\":\"Patterns_and_Ethnic\",\"10\":\"Signs_and_Symbols\",\"11\":\"Spiritual\",\"12\":\"Sports\",\"13\":\"Superheroes\",\n",
    "              \"14\":\"Typography\",\"15\":\"Vintage\"}\n",
    "    \n",
    "y = np.array([params[str(i)] for i in np.argmax(predictions, axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result1 = pd.DataFrame(X_test_id, columns=['id'])\n",
    "result1.loc[:, 'Mobile_Theme'] = pd.Series(y, index=result1.index)\n",
    "now = datetime.datetime.now()\n",
    "sub_file = 'submission_keras_v1' +  '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "result1.to_csv(sub_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
